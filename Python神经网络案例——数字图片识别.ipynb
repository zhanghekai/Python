{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid fintion expit()\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# neural network class definition\n",
    "class neuralNetwork :\n",
    "    \n",
    "    # initialise the neural network numpy.transpose(inputs))\n",
    "    # 1.å®šä¹‰èŠ‚ç‚¹æ•°é‡ï¼›2.éšæœºåˆå§‹æƒé‡ï¼›3.å®šä¹‰å­¦ä¹ ç‡ï¼›4.è®¾ç½®æ¿€æ´»å‡½æ•°\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningreat) :\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight martices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        '''ä½¿ç”¨æ­£æ€æ¦‚ç‡åˆ†å¸ƒé‡‡æ ·æƒé‡ï¼Œå…¶ä¸­å¹³å‡å€¼ä¸º0ï¼Œæ ‡å‡†æ–¹å·®ä¸ºèŠ‚ç‚¹ä¼ å…¥é“¾æ¥æ•°çš„å¼€æ–¹'''\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learningreat\n",
    "        \n",
    "        # activation function is the sigoid function\n",
    "        # åŒ¿åå‡½æ•°lambdaæ¥å—äº†xï¼Œè¿”å›scipy.special.expit(x)ï¼Œè¿™å°±æ˜¯Så‡½æ•°\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "                                     \n",
    "        pass\n",
    "    \n",
    "    def train(self, inputs_list, targets_list) :\n",
    "        # å°†è¾“å…¥åˆ—è¡¨è½¬æ¢ä¸ºäºŒç»´æ•°ç»„\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #caulate signals into hidden/final_output layer\n",
    "        #calculate tesignals emerging from hidden/final_output layer\n",
    "        '''è¾“å…¥ä¿¡å·X_HIDDEN = W_input_hidden * I'''\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs) # è®¡ç®—éšè—å±‚ä¸­çš„è¾“å…¥ä¿¡å·\n",
    "        hidden_outputs =self.activation_function(hidden_inputs) # ç”¨æ¿€æ´»å‡½æ•°è®¡ç®—éšè—å±‚ä¸­å‡ºç°çš„ä¿¡å·\n",
    "        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weight for the links between the hidden/input andoutput/hidden layers\n",
    "        # ğŸ”ºW_j,k = a * E_k * O_k (1 - O_k) Â· (O_j).T\n",
    "        # * ä»£è¡¨æ­£å¸¸çš„å¯¹åº”å…ƒç´ çš„ä¹˜æ³•ï¼›Â· ç‚¹ä¹˜æ˜¯çŸ©é˜µç‚¹ç§¯\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), \n",
    "                                       numpy.transpose(hidden_outputs))\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), \n",
    "                                       numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # query the neural network(ç»™å®šè¾“å…¥ï¼Œä»è¾“å‡ºèŠ‚ç‚¹ç»™å‡ºç­”æ¡ˆ)\n",
    "    # 1.æ¥å—è¾“å…¥ï¼›2.å°†ä¿¡å·è°ƒæ•´åˆ°ä¸‹ä¸€å±‚ï¼Œå¹¶åœ¨ä¸‹ä¸€å±‚å†…è°ƒç”¨Så‡½æ•°;3.è¿”å›æœ€ç»ˆè¾“å‡ºç»“æœ\n",
    "    def query(self, inputs_list) :\n",
    "        # å°†è¾“å…¥åˆ—è¡¨è½¬æ¢ä¸ºäºŒç»´æ•°ç»„\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        #caulate signals into hidden/final_output layer\n",
    "        #calculate tesignals emerging from hidden/final_output layer\n",
    "        '''è¾“å…¥ä¿¡å·X_HIDDEN = W_input_hidden * I'''\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs) # è®¡ç®—éšè—å±‚ä¸­çš„è¾“å…¥ä¿¡å·\n",
    "        hidden_outputs =self.activation_function(hidden_inputs) # ç”¨æ¿€æ´»å‡½æ•°è®¡ç®—éšè—å±‚ä¸­å‡ºç°çš„ä¿¡å·\n",
    "        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output node\n",
    "input_nodes = 784 # ä¸ºä»€ä¹ˆé€‰æ‹©784ä¸ªè¾“å…¥èŠ‚ç‚¹å‘¢ï¼Ÿè¿™æ˜¯28Ã—28çš„ç»“æœï¼Œå³å›¾åƒåƒç´ ä¸ªæ•°\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learningrate is 0.1\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance f neural network\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸€äº›æ”¹è¿›ï¼š  \n",
    "    1.è°ƒæ•´å­¦ä¹ ç‡\n",
    "    2.å¤šæ¬¡è¿è¡Œ\n",
    "    3.æ”¹å˜ç½‘ç»œå½¢çŠ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"G:\\\\desktop\\\\mnist_train .csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# train the neural network\n",
    "\n",
    "'''æœ‰äº›äººæŠŠè®­ç»ƒé›†æ‰§è¡Œä¸€æ¬¡ç§°ä¸ºä¸€ä¸ªä¸–ä»£ã€‚å…·æœ‰10ä¸ªä¸–ä»£çš„è®­ç»ƒï¼Œæ„å‘³ç€ä½¿ç”¨æ•´ä¸ªè®­ç»ƒæ•°æ®è¿è¡Œç¨‹åº10æ¬¡ã€‚\n",
    "   é€šè¿‡æä¾›æ›´å¤šçˆ¬ä¸‹å¡çš„æœºä¼šï¼Œæœ‰åŠ©äºåœ¨æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­è¿›è¡Œæƒé‡æ›´æ–°'''\n",
    "# epochs is the number of times the training data set is used for training\n",
    "# epochsæ˜¯è®­ç»ƒæ•°æ®é›†ç”¨äºè®­ç»ƒçš„æ¬¡æ•°\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs) :\n",
    "    # go through all records in the training data set\n",
    "    # æµè§ˆæ•°æ®é›†ä¸­çš„æ‰€æœ‰è®°å½•\n",
    "    for record in training_data_list :\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',') # æ ¹æ®é€—å·å°†æ•°æ®è¿›è¡Œæ‹†åˆ†\n",
    "        # scale and shift the inputs\n",
    "        '''å› ä¸ºæ¿€æ´»å‡½æ•°çš„ç¼˜æ•…ï¼Œè¾“å‡ºå€¼èŒƒå›´åªèƒ½æ˜¯ï¼ˆ0ï¼Œ1ï¼‰ï¼Œå¦‚æœè¾“å…¥æ•°æ®å’Œè¾“å‡ºå€¼å½¢çŠ¶æ­£å¥½é€‚åˆï¼Œ\n",
    "           å°±å¯ä»¥å¾…åœ¨ç½‘ç»œèŠ‚ç‚¹æ¿€æ´»å‡½æ•°çš„èˆ’é€‚åŒºå†…\n",
    "               1.å°†è¾“å…¥é¢œè‰²å€¼ä»è¾ƒå¤§çš„0åˆ°255çš„èŒƒå›´ï¼Œç¼©æ”¾è‡³è¾ƒå°çš„0.01åˆ°1çš„èŒƒå›´\n",
    "               2.å°†æ‰€å¾—åˆ°çš„è¾“å…¥ä¹˜ä»¥0.99ï¼ŒæŠŠå®ƒä»¬çš„èŒƒå›´å˜æˆ0.0åˆ°0.99ï¼Œå†åŠ ä¸Š0.01ï¼Œ\n",
    "                 å°†è¿™äº›å€¼æ•´ä½“åç§»åˆ°æ‰€éœ€çš„èŒƒå›´0.01åˆ°1.00'''\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        \n",
    "        # create the target output values(all 0.01, except the desired label which is 0.99)\n",
    "        '''æ­£ç¡®çš„ç›®æ ‡æ˜¯ï¼šé™¤äº†ç›®æ ‡æ ‡ç­¾å€¼ä¸º0.99ï¼Œå…¶ä½™å€¼ä¸º0.01'''\n",
    "        targets = numpy.zeros(output_nodes) + 0.01 \n",
    "        # all_value[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99 # æ•°æ®ä¸­ç¬¬ä¸€ä¸ªå€¼æ˜¯æ ‡ç­¾ï¼Œå³ä¹¦å†™è€…å®é™…å¸Œæœ›è¡¨ç¤ºçš„æ•°å­—\n",
    "        n.train(inputs,targets) # è°ƒç”¨è®­ç»ƒå‡½æ•°ï¼Œæ¯ä¸€å¹…å›¾ç‰‡è®­ç»ƒä¸€æ¬¡\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"G:\\\\desktop\\\\mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network perform, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list :\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',') # ç”¨é€—å·æ‹†åˆ†æ–‡æœ¬è®°å½•ï¼Œåˆ†ç¦»å‡ºæ•°å€¼\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0]) # è®°ä¸‹ç¬¬ä¸€ä¸ªæ•°å­—ï¼Œè¿™æ˜¯æ­£ç¡®ç­”æ¡ˆ\n",
    "    # scale and shift the inputs\n",
    "    # é‡æ–°è°ƒæ•´å‰©ä¸‹çš„å€¼ï¼Œè®©ä»–ä»¬é€‚åˆç”¨äºæŸ¥è¯¢ç¥ç»ç½‘ç»œ\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs) # å°†æ¥è‡ªç¥ç»ç½‘ç»œçš„å›ç­”ä¿å­˜åœ¨outputså˜é‡ä¸­\n",
    "    \n",
    "    '''numpy.argmax()è¿”å›æœ€å¤§å€¼çš„ç´¢å¼•ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªå‚æ•°axisï¼Œé»˜è®¤æ˜¯0ï¼Œè¡¨ç¤ºå“ªä¸€ç»´çš„æœ€å¤§å€¼ç´¢å¼•ã€‚'''\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs) # è¿”å›æœ€å¤§å€¼ç´¢å¼•\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label) : # å°†æ ‡ç­¾ä¸å·²çŸ¥çš„æ­£ç¡®æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œå¦‚æœä»–ä»¬æ˜¯ç›¸åŒçš„ï¼Œè®¡åˆ†å¡è®°â€œ1â€ï¼Œå¦åˆ™è®°â€œ0â€\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else :\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9736\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "# è®¡ç®—ç»©æ•ˆå¾—åˆ†ï¼Œæ­£ç¡®ç­”æ¡ˆçš„åˆ†æ•°\n",
    "scorecard_array = numpy.asarray(scorecard) # å°†åˆ—è¡¨è½¬å˜ä¸ºä¸€ç»´æ•°ç»„\n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
